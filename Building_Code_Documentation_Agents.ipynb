{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Code Documentation Agents with CrewAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to create a crew of multiple Agents for writing documentation using CrewAI Flows.\n",
    "The crew will analyze code from any public GitHub repository and generate comprehensive documentation\n",
    "by working collaboratively using specialized agents with different roles and responsibilities.\n",
    "CrewAI Flows enable coordinated execution and communication between agents to produce high-quality\n",
    "documentation for any codebase.\n",
    "\n",
    "You will use NVIDIA NIM Microservices for the LLM, llama-3.3-70b. In addition, a NIM for an NVIDIA text embedding model, nv-embedqa-e5-v5, is used. \n",
    "\n",
    "You can get started by leveraging NVIDIA API Catalog and call a hosted model's NIM API Endpoint. Once you familiarize yourself with this blueprint, you may want to self-host models with NVIDIA NIM Microservices.\n",
    "\n",
    "Here's an architecture diagram of the workflow.\n",
    "![arch diagram](./arch_diagram.png)\n",
    "\n",
    "The system employs a multi-agent workflow divided into two key stages:\n",
    "1. Codebase Analysis and Strategy Planning:\n",
    "    - Analyze Codebase: Planner agents inspect the repository to map its structure, identify key components, and understand interdependencies.\n",
    "    - Develop Strategy: They create a tailored documentation plan based on the analysis.\n",
    "2. Documentation Creation and Review:\n",
    "    - High-Level Documentation: One agent generates clear, comprehensive documentation introducing the project and its architecture.\n",
    "    - Quality Assurance: Another agent ensures accuracy, consistency, and completeness across all documentation.\n",
    "\n",
    "\n",
    "\n",
    "# Content Overview\n",
    ">[Prerequisites](#Prerequisites)  \n",
    ">[Define the project URL](#Define-the-project-URL)  \n",
    ">[Create Planning Crew](#Create-Planning-Crew)  \n",
    ">[Create Documentation Crew](#Create-Documentation-Crew)  \n",
    ">[Run Documentation Flow](#Run-Documentation-Flow)  \n",
    "________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Setup\n",
    "Initial imports for the CrewAI Flow and Crew and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Importing Crew related components\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "# Importing CrewAI Flow related components\n",
    "from crewai.flow.flow import Flow, listen, start\n",
    "\n",
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys\n",
    "Prior to getting started, you will need to create API Keys for the NVIDIA API Catalog.\n",
    "\n",
    "- NVIDIA API Catalog\n",
    "  1. Navigate to **[NVIDIA API Catalog](https://build.nvidia.com/explore/discover)**.\n",
    "  2. Select any model, such as llama-3.3-70b-instruct.\n",
    "  3. On the right panel above the sample code snippet, click on \"Get API Key\". This will prompt you to log in if you have not already.\n",
    "\n",
    "### Export API Keys\n",
    "\n",
    "Save this API Key as environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_NIM_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_NIM_API_KEY\"] = nvapi_key\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the NVIDIA API Catalog\n",
    "Let's test the API endpoint. The NVIDIA NIM Microservices used in this notebook are llama-3.3-70b and an NVIDIA text embedding model, nv-embedqa-e5-v5. These are models are defined in the yaml files in the `config` directory if you're looking for them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "\n",
    "response = completion(\n",
    "    model=\"nvidia_nim/meta/llama-3.3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's a good name for a dog?\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Locally Run NVIDIA NIM Microservices\n",
    "\n",
    "Once you familiarize yourself with this blueprint, you may want to self-host models with NVIDIA NIM Microservices using NVIDIA AI Enterprise software license. This gives you the ability to run models anywhere, giving you ownership of your customizations and full control of your intellectual property (IP) and AI applications.\n",
    "\n",
    "[Learn more about NIM Microservices](https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/)\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>NOTE:</b> Run the following cell only if you're using a local NIM Microservice instead of the API Catalog Endpoint.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "# connect to an embedding NIM running at localhost:8000, specifying a model\n",
    "llm = ChatNVIDIA(base_url=\"http://localhost:8000/v1\", model=\"meta/llama-3.3-70b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the project URL\n",
    "\n",
    "In this demo, a sample repository is provided for you. However, feel fry to test this on other public repositories! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_url = \"https://github.com/triton-inference-server/server\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for our Flow\n",
    "\n",
    "1. Clone the repository for the project\n",
    "2. Plan the documentation for the project **[Crew of Agents]** \n",
    "3. Create the documentation for the project **[Crew of Agents]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![CrewAIFlow.png](crewai-nim-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Planning Crew\n",
    "\n",
    "Initial strucutre data we will use to capture the output of the planning crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data structures to capture documentation planning output\n",
    "class DocItem(BaseModel):\n",
    "    \"\"\"Represents a documentation item\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    prerequisites: str\n",
    "    examples: list[str]\n",
    "    goal: str\n",
    "\n",
    "class DocPlan(BaseModel):\n",
    "    \"\"\"Documentation plan\"\"\"\n",
    "    overview: str\n",
    "    docs: list[DocItem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing for Llama 3.3 Prompting Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents Prompting Template for Llama 3.3\n",
    "system_template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>\"\"\"\n",
    "prompt_template=\"\"\"<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>\"\"\"\n",
    "response_template=\"\"\"<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    ")\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/planner_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/planner_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)\n",
    "\n",
    "code_explorer = Agent(\n",
    "  config=agents_config['code_explorer'],\n",
    "  system_template=system_template,\n",
    "  prompt_template=prompt_template,\n",
    "  response_template=response_template,\n",
    "  tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "  ]\n",
    ")\n",
    "documentation_planner = Agent(\n",
    "  config=agents_config['documentation_planner'],\n",
    "  system_template=system_template,\n",
    "  prompt_template=prompt_template,\n",
    "  response_template=response_template,\n",
    "  tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "  ]\n",
    ")\n",
    "\n",
    "analyze_codebase = Task(\n",
    "  config=tasks_config['analyze_codebase'],\n",
    "  agent=code_explorer\n",
    ")\n",
    "create_documentation_plan = Task(\n",
    "  config=tasks_config['create_documentation_plan'],\n",
    "  agent=documentation_planner,\n",
    "  output_pydantic=DocPlan\n",
    ")\n",
    "\n",
    "planning_crew = Crew(\n",
    "    agents=[code_explorer, documentation_planner],\n",
    "    tasks=[analyze_codebase, create_documentation_plan],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Documentation Crew\n",
    "\n",
    "Crew of AI Agents to execute the documentation plan and create the documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for the documentation crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "from crewai_tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ValidateMermaidInput(BaseModel):\n",
    "    \"\"\"Input schema for ValidateMermaidTool.\"\"\"\n",
    "    text: str = Field(..., description=\"Mermaid diagram text to validate.\")\n",
    "\n",
    "class ValidateMermaidTool(BaseTool):\n",
    "    name: str = \"Validate Mermaid Diagram\"\n",
    "    description: str = (\n",
    "        \"Validates Mermaid diagram syntax, specifically checking for proper arrow syntax \"\n",
    "        \"and ensuring there are no invalid trailing '>' characters or malformed pipe ('|') decorators.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ValidateMermaidInput\n",
    "\n",
    "    def _run(self, text: str) -> bool:\n",
    "        # Check for invalid trailing > in arrow syntax\n",
    "        if \"|>\" in text:\n",
    "            return False\n",
    "\n",
    "        # Check for valid arrow syntax\n",
    "        valid_arrows = [\"-->\", \"---\", \"---|\", \"|---|\"]\n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if any(arrow in line for arrow in valid_arrows):\n",
    "                # Verify arrow syntax is properly formatted\n",
    "                parts = line.split()\n",
    "                for part in parts:\n",
    "                    if part.startswith(\"|\") and not part.endswith(\"|\"):\n",
    "                        return False\n",
    "                    if part.endswith(\">\") and not part.startswith(\"-\"):\n",
    "                        return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    "    WebsiteSearchTool\n",
    ")\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/documentation_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/documentation_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)\n",
    "\n",
    "overview_writer = Agent(config=agents_config['overview_writer'], tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool(),\n",
    "    ValidateMermaidTool(),\n",
    "    WebsiteSearchTool(\n",
    "      website=\"https://mermaid.js.org/syntax/examples.html\",\n",
    "      config=dict(\n",
    "        embedder=dict(\n",
    "            provider=\"nvidia\",\n",
    "            config=dict(\n",
    "                model=\"nvdev/nvidia/nv-embedqa-e5-v5\"\n",
    "            ),\n",
    "        ),\n",
    "      )\n",
    "    )\n",
    "])\n",
    "\n",
    "documentation_reviewer = Agent(config=agents_config['documentation_reviewer'], tools=[\n",
    "    DirectoryReadTool(directory=\"docs/\", name=\"Check existing documentation folder\"),\n",
    "    ValidateMermaidTool(),\n",
    "    FileReadTool(),\n",
    "])\n",
    "\n",
    "draft_documentation = Task(\n",
    "  config=tasks_config['draft_documentation'],\n",
    "  agent=overview_writer\n",
    ")\n",
    "\n",
    "qa_review_documentation = Task(\n",
    "  config=tasks_config['qa_review_documentation'],\n",
    "  agent=documentation_reviewer\n",
    ")\n",
    "\n",
    "documentation_crew = Crew(\n",
    "    agents=[overview_writer, documentation_reviewer],\n",
    "    tasks=[draft_documentation, qa_review_documentation],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Documentation Flow\n",
    "\n",
    "A Flow to create the documentation for the project where we will use the planning crew to plan the documentation and the documentation crew to create the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentationState(BaseModel):\n",
    "  \"\"\"\n",
    "  State for the documentation flow\n",
    "  \"\"\"\n",
    "  project_url: str = project_url\n",
    "  repo_path: Path = \"workdir/\"\n",
    "\n",
    "class CreateDocumentationFlow(Flow[DocumentationState]):\n",
    "  # Clone the repository, initial step\n",
    "  # No need for AI Agents on this step, so we just use regular Python code\n",
    "  @start()\n",
    "  def clone_repo(self):\n",
    "    print(f\"# Cloning repository: {self.state.project_url}\")\n",
    "    # Extract repo name from URL\n",
    "    repo_name = self.state.project_url.split(\"/\")[-1]\n",
    "    self.state.repo_path = f\"{self.state.repo_path}{repo_name}\"\n",
    "\n",
    "    # Clone the repository\n",
    "    subprocess.run([\"git\", \"clone\", self.state.project_url, self.state.repo_path])\n",
    "    return self.state\n",
    "\n",
    "  @listen(clone_repo)\n",
    "  def plan_docs(self):\n",
    "    print(f\"# Planning documentation for: {self.state.repo_path}\")\n",
    "    result = planning_crew.kickoff(inputs={'repo_path': self.state.repo_path})\n",
    "    print(f\"# Planned docs for {self.state.repo_path}:\")\n",
    "    for doc in result.pydantic.docs:\n",
    "        print(f\"    - {doc.title}\")\n",
    "    return result\n",
    "\n",
    "  @listen(plan_docs)\n",
    "  def save_plan(self, plan):\n",
    "    with open(\"docs/plan.json\", \"w\") as f:\n",
    "      f.write(plan.raw)\n",
    "\n",
    "  @listen(plan_docs)\n",
    "  def create_docs(self, plan):\n",
    "    for doc in plan.pydantic.docs:\n",
    "      print(f\"# Creating documentation for: {doc.title}\")\n",
    "      result = documentation_crew.kickoff(inputs={\n",
    "        'repo_path': self.state.repo_path,\n",
    "        'title': doc.title,\n",
    "        'overview': plan.pydantic.overview,\n",
    "        'description': doc.description,\n",
    "        'prerequisites': doc.prerequisites,\n",
    "        'examples': doc.examples,\n",
    "        'goal': doc.goal\n",
    "      })\n",
    "\n",
    "      # Save documentation to file in docs folder\n",
    "      docs_dir = Path(\"docs\")\n",
    "      docs_dir.mkdir(exist_ok=True)\n",
    "      title = doc.title.lower().replace(\" \", \"_\") + \".mdx\"\n",
    "      with open(docs_dir / title, \"w\") as f:\n",
    "          f.write(result.raw)\n",
    "    print(f\"# Documentation created for: {self.state.repo_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing helper methods to plot and execute the flow in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the flow\n",
    "flow = CreateDocumentationFlow()\n",
    "flow.plot()\n",
    "\n",
    "# Display the flow visualization using IFrame\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Display the flow visualization\n",
    "IFrame(src='./crewai_flow.html', width='100%', height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Documentation Flow\n",
    "\n",
    "After running this cell, check the `docs` directory for the generated documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = CreateDocumentationFlow()\n",
    "flow.kickoff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
