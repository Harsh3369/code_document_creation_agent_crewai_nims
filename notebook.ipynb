{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Writing Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to create an AI crew for writing documentation using CrewAI Flows.\n",
    "The crew will analyze code from any public GitHub repository and generate comprehensive documentation\n",
    "by working collaboratively using specialized agents with different roles and responsibilities.\n",
    "CrewAI Flows enable coordinated execution and communication between agents to produce high-quality\n",
    "documentation for any codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Setup\n",
    "Initial imports for the CrewAI Flow and Crew and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import getpass\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Importing Crew related components\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "# Importing CrewAI Flow related components\n",
    "from crewai.flow.flow import Flow, listen, start\n",
    "\n",
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Setting up the environment\n",
    "os.environ[\"NVIDIA_NIM_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA NIM API key: \")\n",
    "os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the project URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_url = \"https://github.com/langchain-ai/langchain-nvidia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for our Flow\n",
    "\n",
    "1. Clone the repository for the project\n",
    "2. Plan the documentation for the project **[Crew of Agents]** \n",
    "3. Create the documentation for the project **[Crew of Agents]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![CrewAIFlow.png](crewai-nim-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optmizing for Llama 3.3 Prompting Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents Prompting Template for Llama 3.3\n",
    "system_template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>\"\"\"\n",
    "prompt_template=\"\"\"<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>\"\"\"\n",
    "response_template=\"\"\"<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Planning Crew\n",
    "\n",
    "Initial strucutre data we will use to capture the output of the planning crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data structures to capture documentation planning output\n",
    "class DocItem(BaseModel):\n",
    "    \"\"\"Represents a documentation item\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    prerequisites: str\n",
    "    examples: list[str]\n",
    "    goal: str\n",
    "\n",
    "class DocPlan(BaseModel):\n",
    "    \"\"\"Documentation plan\"\"\"\n",
    "    overview: str\n",
    "    docs: list[DocItem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaomoura/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    ")\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/planner_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/planner_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)\n",
    "\n",
    "code_explorer = Agent(\n",
    "  config=agents_config['code_explorer'],\n",
    "  system_template=system_template,\n",
    "  prompt_template=prompt_template,\n",
    "  response_template=response_template,\n",
    "  tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "  ]\n",
    ")\n",
    "documentation_planner = Agent(\n",
    "  config=agents_config['documentation_planner'],\n",
    "  system_template=system_template,\n",
    "  prompt_template=prompt_template,\n",
    "  response_template=response_template,\n",
    "  tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool()\n",
    "  ]\n",
    ")\n",
    "\n",
    "analyze_codebase = Task(\n",
    "  config=tasks_config['analyze_codebase'],\n",
    "  agent=code_explorer\n",
    ")\n",
    "create_documentation_plan = Task(\n",
    "  config=tasks_config['create_documentation_plan'],\n",
    "  agent=documentation_planner,\n",
    "  output_pydantic=DocPlan\n",
    ")\n",
    "\n",
    "planning_crew = Crew(\n",
    "    agents=[code_explorer, documentation_planner],\n",
    "    tasks=[analyze_codebase, create_documentation_plan],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "from crewai_tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ValidateMermaidInput(BaseModel):\n",
    "    \"\"\"Input schema for ValidateMermaidTool.\"\"\"\n",
    "    text: str = Field(..., description=\"Mermaid diagram text to validate.\")\n",
    "\n",
    "class ValidateMermaidTool(BaseTool):\n",
    "    name: str = \"Validate Mermaid Diagram\"\n",
    "    description: str = (\n",
    "        \"Validates Mermaid diagram syntax, specifically checking for proper arrow syntax \"\n",
    "        \"and ensuring there are no invalid trailing '>' characters or malformed pipe ('|') decorators.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ValidateMermaidInput\n",
    "\n",
    "    def _run(self, text: str) -> bool:\n",
    "        # Check for invalid trailing > in arrow syntax\n",
    "        if \"|>\" in text:\n",
    "            return False\n",
    "\n",
    "        # Check for valid arrow syntax\n",
    "        valid_arrows = [\"-->\", \"---\", \"---|\", \"|---|\"]\n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if any(arrow in line for arrow in valid_arrows):\n",
    "                # Verify arrow syntax is properly formatted\n",
    "                parts = line.split()\n",
    "                for part in parts:\n",
    "                    if part.startswith(\"|\") and not part.endswith(\"|\"):\n",
    "                        return False\n",
    "                    if part.endswith(\">\") and not part.startswith(\"-\"):\n",
    "                        return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Documentation Crew\n",
    "\n",
    "Crew of AI Agents to execute the documentation plan and create the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 03:54:07,280 - 8071896128 - __init__.py-__init__:521 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    "    WebsiteSearchTool\n",
    ")\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/documentation_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/documentation_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)\n",
    "\n",
    "overview_writer = Agent(\n",
    "  config=agents_config['overview_writer'],\n",
    "  system_template=system_template,\n",
    "  prompt_template=prompt_template,\n",
    "  response_template=response_template,\n",
    "  tools=[\n",
    "    DirectoryReadTool(),\n",
    "    FileReadTool(),\n",
    "    ValidateMermaidTool(),\n",
    "    WebsiteSearchTool(\n",
    "      website=\"https://mermaid.js.org/syntax/examples.html\",\n",
    "      config=dict(\n",
    "        embedder=dict(\n",
    "            provider=\"nvidia\",\n",
    "            config=dict(\n",
    "                model=\"nvidia/nv-embedqa-e5-v5\"\n",
    "            ),\n",
    "        ),\n",
    "      )\n",
    "    )\n",
    "])\n",
    "\n",
    "documentation_reviewer = Agent(\n",
    "  config=agents_config['documentation_reviewer'],\n",
    "  system_template=system_template,\n",
    "  prompt_template=prompt_template,\n",
    "  response_template=response_template,\n",
    "  tools=[\n",
    "    DirectoryReadTool(directory=\"docs/\", name=\"Check existing documentation folder\"),\n",
    "    ValidateMermaidTool(),\n",
    "    FileReadTool(),\n",
    "  ]\n",
    ")\n",
    "\n",
    "draft_documentation = Task(\n",
    "  config=tasks_config['draft_documentation'],\n",
    "  agent=overview_writer\n",
    ")\n",
    "\n",
    "qa_review_documentation = Task(\n",
    "  config=tasks_config['qa_review_documentation'],\n",
    "  agent=documentation_reviewer\n",
    ")\n",
    "\n",
    "documentation_crew = Crew(\n",
    "    agents=[overview_writer, documentation_reviewer],\n",
    "    tasks=[draft_documentation, qa_review_documentation],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Documentation Flow\n",
    "\n",
    "A Flow to create the documentation for the project where we will use the planning crew to plan the documentation and the documentation crew to create the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentationState(BaseModel):\n",
    "  \"\"\"\n",
    "  State for the documentation flow\n",
    "  \"\"\"\n",
    "  project_url: str = project_url\n",
    "  repo_path: Path = \"workdir/\"\n",
    "\n",
    "class CreateDocumentationFlow(Flow[DocumentationState]):\n",
    "  # Clone the repository, initial step\n",
    "  # No need for AI Agents on this step, so we just use regular Python code\n",
    "  @start()\n",
    "  def clone_repo(self):\n",
    "    print(f\"# Cloning repository: {self.state.project_url}\")\n",
    "    # Extract repo name from URL\n",
    "    repo_name = self.state.project_url.split(\"/\")[-1]\n",
    "    self.state.repo_path = f\"{self.state.repo_path}{repo_name}\"\n",
    "\n",
    "    # Clone the repository\n",
    "    subprocess.run([\"git\", \"clone\", self.state.project_url, self.state.repo_path])\n",
    "    return self.state\n",
    "\n",
    "  @listen(clone_repo)\n",
    "  def plan_docs(self):\n",
    "    print(f\"# Planning documentation for: {self.state.repo_path}\")\n",
    "    result = planning_crew.kickoff(inputs={'repo_path': self.state.repo_path})\n",
    "    print(f\"# Planned docs for {self.state.repo_path}:\")\n",
    "    for doc in result.pydantic.docs:\n",
    "        print(f\"    - {doc.title}\")\n",
    "    return result\n",
    "\n",
    "  @listen(plan_docs)\n",
    "  def save_plan(self, plan):\n",
    "    with open(\"docs/plan.json\", \"w\") as f:\n",
    "      f.write(plan.raw)\n",
    "\n",
    "  @listen(plan_docs)\n",
    "  def create_docs(self, plan):\n",
    "    for doc in plan.pydantic.docs:\n",
    "      print(f\"# Creating documentation for: {doc.title}\")\n",
    "      result = documentation_crew.kickoff(inputs={\n",
    "        'repo_path': self.state.repo_path,\n",
    "        'title': doc.title,\n",
    "        'overview': plan.pydantic.overview,\n",
    "        'description': doc.description,\n",
    "        'prerequisites': doc.prerequisites,\n",
    "        'examples': doc.examples,\n",
    "        'goal': doc.goal\n",
    "      })\n",
    "\n",
    "      # Save documentation to file in docs folder\n",
    "      docs_dir = Path(\"docs\")\n",
    "      docs_dir.mkdir(exist_ok=True)\n",
    "      title = doc.title.lower().replace(\" \", \"_\") + \".mdx\"\n",
    "      with open(docs_dir / title, \"w\") as f:\n",
    "          f.write(result.raw)\n",
    "    print(f\"# Documentation created for: {self.state.repo_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing helper methods to plot and execute the flow in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as crewai_flow.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"./crewai_flow.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2979a4810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the flow\n",
    "flow = CreateDocumentationFlow()\n",
    "flow.plot()\n",
    "\n",
    "# Display the flow visualization using IFrame\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Display the flow visualization\n",
    "IFrame(src='./crewai_flow.html', width='100%', height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Cloning repository: https://github.com/langchain-ai/langchain-nvidia\n",
      "# Planning documentation for: workdir/langchain-nvidia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'workdir/langchain-nvidia' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Planned docs for workdir/langchain-nvidia:\n",
      "    - Introduction to LangChain NVIDIA\n",
      "    - Getting Started with LangChain NVIDIA\n",
      "    - Architecture and Design of LangChain NVIDIA\n",
      "    - Using LangChain NVIDIA for AI Applications\n",
      "    - Advanced Topics in LangChain NVIDIA\n",
      "# Creating documentation for: Introduction to LangChain NVIDIA\n",
      "# Creating documentation for: Getting Started with LangChain NVIDIA\n",
      "# Creating documentation for: Architecture and Design of LangChain NVIDIA\n",
      "# Creating documentation for: Using LangChain NVIDIA for AI Applications\n",
      "# Creating documentation for: Advanced Topics in LangChain NVIDIA\n",
      "# Documentation created for: workdir/langchain-nvidia\n"
     ]
    }
   ],
   "source": [
    "flow = CreateDocumentationFlow()\n",
    "flow.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
